{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2a40732",
   "metadata": {},
   "source": [
    "### `YOLO (You Only Look Once)` Algorithm\n",
    "\n",
    "- It is an `Object Detection Algorithm` in the field of **Computer Vision**.\n",
    "- Suppose if we want to detect whether the object in the image is a `Dog` or a `Man`? We use `Image Classification` technique. But if we need to do `Object Localization` i.e. we also need to specify the `Bounding Box` (position of the object within the image)\n",
    "\n",
    "<img src=\"images/cnn/yolo1.png\" width=800px>\n",
    "\n",
    "\n",
    "- Now to do the above `Object Localization` task in neural network output we can have a vector where we classify the probability of the class using $P_{c}$. Here if there is a `Dog` or a `Person` the number will be `1` or else `0`. Then the coordinates of the `Bounding Box` are ($B_{x}$, $B_{y}$, $B_{w}$, $B_{h}$). Where the center of the box ($B_{x}$, $B_{y}$) highlighted using the **yellow dot** in the image, and ($B_{w}$, $B_{h}$) is the width and height of the box.\n",
    "- So if there is some object in the image the value of $P_{c}$ will be `1` and if there is no object to detect in the image the value will be `0`. And according to the class of the object the value of $C_{1}$ or $C_{2}$ get decided.\n",
    "\n",
    "<img src=\"images/cnn/yolo2.png\" width=800px>\n",
    "\n",
    "- After doing the above we can train the neural networks to detect and classify the object as well as the `Bounding Box`.\n",
    "\n",
    "<img src=\"images/cnn/yolo3.png\" width=800px>\n",
    "\n",
    "- So after we train our model it will be able to detect and classify that particular object in an image as well as the `Bounding Box` around that object. So basically it answers the `Object Localization`.\n",
    "\n",
    "<img src=\"images/cnn/yolo4.png\" width=800px>\n",
    "\n",
    "\n",
    "- But it only works okay with single object. But if there are multiple objects in an image? In this case it becomes very hard to determine the dimension of the neural network output as there can be `n` number of objects in the image.\n",
    "\n",
    "<img src=\"images/cnn/yolo5.png\" width=800px>\n",
    "\n",
    "- To solve this problem `YOLO` algorith divides the image into different grid cells as here we are dividing the upper image into `4 X 4` grids.\n",
    "\n",
    "<img src=\"images/cnn/yolo6.png\" width=800px>\n",
    "\n",
    "- And then for each of the grid cells we can encode (Come up with the vector $P_{c}$ as earlier). If there is no object in the cell the value of $P_{c}$ will be `0`. But if there are multiple objects in a cell, as here (remember when an object takes multiple cells then we need to find the center of that object as here highlighted by a yellow circle for both the objects) then the value of $P_{c}$ gets decided whether the center of that object is in that cell or not. As here even though both the `dog` and the `person` are present in that cell but only the center of `dog` is presented in that cell means that cell belongs to the `dog` object. And the grid cell that holds the center of the person will belong to the `person` object.\n",
    "- At the end we will have a `4 X 4 X 7` (4 by 4 cells each cell has a vector of 7).\n",
    "\n",
    "<img src=\"images/cnn/yolo7.png\" width=800px>\n",
    "\n",
    "\n",
    "- After this we can create our training dataset that will have so many such images where each image will have Bounding rectangle, and based on that we will try to derive the object. As here we are using `4 X 4` cells so there will be `16` such vectors per training sample or per training image. Using this we can train the neural network, and after that it can do predictions.\n",
    "\n",
    "<img src=\"images/cnn/yolo8.png\" width=800px>\n",
    "<img src=\"images/cnn/yolo9.png\" width=800px>\n",
    "\n",
    "- This algorithm is named **You Only Look Once** because it doesnot get repeated. Here in one `Forward Pass` all the predictions are done.\n",
    "\n",
    "<hr style=\"border:2px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127789a8",
   "metadata": {},
   "source": [
    "- This is a Basic algorithm so we need some tweaks because there can be a few issues like:\n",
    "  - The algorithm might `detect multiple bounding rectangles for a given object`. As here for the person it detected `2` yellows and `1` white rectangle. And the white rectangle has the highest probability while the other two has less probability.\n",
    "  \n",
    "  <img src=\"images/cnn/yolo10.png\" width=800px>\n",
    "  \n",
    "  - But we cannot just take the maximum probability as because if there is another person. So to solve this problem we use `IOU` i.e. here we select the rectangle with the maximum probability and then all other rectangles of that object and try to find the overlapping area. If the objects are overlapping the value of `IOU` will be more. Then once we find the overlapping rectangles we can discard them.\n",
    "  \n",
    "  <img src=\"images/cnn/yolo11.png\" width=800px>\n",
    "  \n",
    "  \n",
    "  - Then we do the same for the `dog` object also. This technique is called **No max suppression**. So after neural network detected all the objects we need to apply this **No max suppression** and we will get these unique bounding boxes.\n",
    "  \n",
    "  <img src=\"images/cnn/yolo12.png\" width=800px>\n",
    "  \n",
    "  - There can be another issue where `a single cell contains center of two objects`.\n",
    "  \n",
    "  <img src=\"images/cnn/yolo13.png\" width=800px>\n",
    "  \n",
    "  - Here we will have different vectors for `person` and `dog` class. Here instead of having a `7` dimension vectors for each classes we may have a `14` dimension vector where both the vectors get concatinated. This concept is called **Anchor Box**.\n",
    "  \n",
    "  <img src=\"images/cnn/yolo14.png\" width=800px>\n",
    "  \n",
    "  - It is also applicable for more than two objects having center in the same cell. As many centers are there that many **Anchor Boxes** will get used.\n",
    "  - So the CNN with two anchor boxes will have vector size of `14` instead of `7`.\n",
    "  \n",
    "  <img src=\"images/cnn/yolo15.png\" width=800px>\n",
    " \n",
    " \n",
    "- The **YOLO** algorithm is a very very fast algorithm. Even on a video with `40 fps` it can detect objects really fast.\n",
    "\n",
    "<hr style=\"border:2px solid black\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d688ee4",
   "metadata": {},
   "source": [
    "### Practical usage of `YOLO`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2984bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012310c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b220c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe164d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a2cd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
